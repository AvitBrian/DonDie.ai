{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides details about my preprocessing steps for the heart_failure_clinical_records_dataset used in [DonDie.ai](https://github.com/AvitBrian/DonDie.ai)."
      ],
      "metadata": {
        "id": "vpGzPM1Fgim2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOzWlQtDgF3k",
        "outputId": "bf1410d1-8918-40af-ef56-cab6048a816f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.17.0 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.17.0) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.0) (0.1.2)\n",
            "    age  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
            "0  75.0                       582         0                 20   \n",
            "1  55.0                      7861         0                 38   \n",
            "2  65.0                       146         0                 20   \n",
            "3  50.0                       111         0                 20   \n",
            "4  65.0                       160         1                 20   \n",
            "\n",
            "   high_blood_pressure  platelets  serum_creatinine  time  \n",
            "0                    1  265000.00               1.9     4  \n",
            "1                    0  263358.03               1.1     6  \n",
            "2                    0  162000.00               1.3     7  \n",
            "3                    0  210000.00               1.9     7  \n",
            "4                    0  327000.00               2.7     8  \n",
            "Epoch 1/5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5264 - loss: 1.2765 - val_accuracy: 0.6000 - val_loss: 1.2413\n",
            "Epoch 2/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4803 - loss: 1.2746 - val_accuracy: 0.6167 - val_loss: 1.1943\n",
            "Epoch 3/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5056 - loss: 1.2295 - val_accuracy: 0.7167 - val_loss: 1.1533\n",
            "Epoch 4/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5718 - loss: 1.1919 - val_accuracy: 0.7167 - val_loss: 1.1162\n",
            "Epoch 5/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6602 - loss: 1.1454 - val_accuracy: 0.7833 - val_loss: 1.0800\n",
            "Epoch 6/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6774 - loss: 1.0647 - val_accuracy: 0.7833 - val_loss: 1.0446\n",
            "Epoch 7/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6564 - loss: 1.0715 - val_accuracy: 0.7833 - val_loss: 1.0133\n",
            "Epoch 8/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6298 - loss: 1.0553 - val_accuracy: 0.7667 - val_loss: 0.9879\n",
            "Epoch 9/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7134 - loss: 0.9623 - val_accuracy: 0.7667 - val_loss: 0.9641\n",
            "Epoch 10/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7377 - loss: 0.9673 - val_accuracy: 0.7667 - val_loss: 0.9393\n",
            "Epoch 11/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7462 - loss: 0.9511 - val_accuracy: 0.7833 - val_loss: 0.9138\n",
            "Epoch 12/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7462 - loss: 0.9377 - val_accuracy: 0.7833 - val_loss: 0.8865\n",
            "Epoch 13/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7716 - loss: 0.8775 - val_accuracy: 0.8000 - val_loss: 0.8565\n",
            "Epoch 14/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7792 - loss: 0.8888 - val_accuracy: 0.8000 - val_loss: 0.8332\n",
            "Epoch 15/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7890 - loss: 0.8770 - val_accuracy: 0.7833 - val_loss: 0.8095\n",
            "Epoch 16/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8398 - loss: 0.8034 - val_accuracy: 0.7833 - val_loss: 0.7915\n",
            "Epoch 17/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8116 - loss: 0.7984 - val_accuracy: 0.7833 - val_loss: 0.7766\n",
            "Epoch 18/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8093 - loss: 0.7844 - val_accuracy: 0.7833 - val_loss: 0.7612\n",
            "Epoch 19/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8207 - loss: 0.7500 - val_accuracy: 0.8000 - val_loss: 0.7442\n",
            "Epoch 20/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8030 - loss: 0.7430 - val_accuracy: 0.7833 - val_loss: 0.7327\n",
            "Epoch 21/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8169 - loss: 0.7646 - val_accuracy: 0.8000 - val_loss: 0.7190\n",
            "Epoch 22/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8551 - loss: 0.7308 - val_accuracy: 0.8167 - val_loss: 0.7019\n",
            "Epoch 23/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8592 - loss: 0.6534 - val_accuracy: 0.8167 - val_loss: 0.6885\n",
            "Epoch 24/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.6510 - val_accuracy: 0.8167 - val_loss: 0.6757\n",
            "Epoch 25/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8268 - loss: 0.6913 - val_accuracy: 0.8167 - val_loss: 0.6649\n",
            "Epoch 26/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8170 - loss: 0.6536 - val_accuracy: 0.8167 - val_loss: 0.6570\n",
            "Epoch 27/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8473 - loss: 0.6556 - val_accuracy: 0.8167 - val_loss: 0.6498\n",
            "Epoch 28/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 0.6313 - val_accuracy: 0.8167 - val_loss: 0.6457\n",
            "Epoch 29/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8270 - loss: 0.6253 - val_accuracy: 0.8167 - val_loss: 0.6425\n",
            "Epoch 30/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8505 - loss: 0.6485 - val_accuracy: 0.8167 - val_loss: 0.6315\n",
            "Epoch 31/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8794 - loss: 0.6097 - val_accuracy: 0.8167 - val_loss: 0.6231\n",
            "Epoch 32/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8486 - loss: 0.6001 - val_accuracy: 0.8167 - val_loss: 0.6144\n",
            "Epoch 33/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8219 - loss: 0.6537 - val_accuracy: 0.8167 - val_loss: 0.6044\n",
            "Epoch 34/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8763 - loss: 0.5871 - val_accuracy: 0.8167 - val_loss: 0.5948\n",
            "Epoch 35/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8809 - loss: 0.5500 - val_accuracy: 0.8167 - val_loss: 0.5902\n",
            "Epoch 36/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8318 - loss: 0.5902 - val_accuracy: 0.8167 - val_loss: 0.5831\n",
            "Epoch 37/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8465 - loss: 0.5891 - val_accuracy: 0.8167 - val_loss: 0.5748\n",
            "Epoch 38/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8491 - loss: 0.5430 - val_accuracy: 0.8000 - val_loss: 0.5673\n",
            "Epoch 39/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.5571 - val_accuracy: 0.8167 - val_loss: 0.5653\n",
            "Epoch 40/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8770 - loss: 0.5354 - val_accuracy: 0.8167 - val_loss: 0.5646\n",
            "Epoch 41/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8517 - loss: 0.5425 - val_accuracy: 0.8167 - val_loss: 0.5599\n",
            "Epoch 42/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8460 - loss: 0.5820 - val_accuracy: 0.8000 - val_loss: 0.5522\n",
            "Epoch 43/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8633 - loss: 0.5380 - val_accuracy: 0.8167 - val_loss: 0.5445\n",
            "Epoch 44/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8236 - loss: 0.5672 - val_accuracy: 0.8167 - val_loss: 0.5424\n",
            "Epoch 45/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8798 - loss: 0.4971 - val_accuracy: 0.8000 - val_loss: 0.5393\n",
            "Epoch 46/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8751 - loss: 0.5565 - val_accuracy: 0.8000 - val_loss: 0.5399\n",
            "Epoch 47/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8746 - loss: 0.5116 - val_accuracy: 0.8000 - val_loss: 0.5389\n",
            "Epoch 48/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 0.5194 - val_accuracy: 0.8000 - val_loss: 0.5371\n",
            "Epoch 49/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8841 - loss: 0.5258 - val_accuracy: 0.8000 - val_loss: 0.5328\n",
            "Epoch 50/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8802 - loss: 0.4825 - val_accuracy: 0.8167 - val_loss: 0.5251\n",
            "Epoch 51/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8543 - loss: 0.5133 - val_accuracy: 0.8167 - val_loss: 0.5223\n",
            "Epoch 52/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8787 - loss: 0.4779 - val_accuracy: 0.8167 - val_loss: 0.5195\n",
            "Epoch 53/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8727 - loss: 0.5142 - val_accuracy: 0.8333 - val_loss: 0.5130\n",
            "Epoch 54/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8696 - loss: 0.4796 - val_accuracy: 0.8333 - val_loss: 0.5120\n",
            "Epoch 55/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8893 - loss: 0.4906 - val_accuracy: 0.8333 - val_loss: 0.5099\n",
            "Epoch 56/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8589 - loss: 0.4823 - val_accuracy: 0.8333 - val_loss: 0.5084\n",
            "Epoch 57/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8292 - loss: 0.5017 - val_accuracy: 0.8333 - val_loss: 0.5100\n",
            "Epoch 58/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8950 - loss: 0.5082 - val_accuracy: 0.8333 - val_loss: 0.5094\n",
            "Epoch 59/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8567 - loss: 0.4696 - val_accuracy: 0.8333 - val_loss: 0.5058\n",
            "Epoch 60/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8897 - loss: 0.4371 - val_accuracy: 0.8167 - val_loss: 0.5037\n",
            "Epoch 61/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8595 - loss: 0.4462 - val_accuracy: 0.8167 - val_loss: 0.5060\n",
            "Epoch 62/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8761 - loss: 0.4259 - val_accuracy: 0.8000 - val_loss: 0.5089\n",
            "Epoch 63/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8305 - loss: 0.5350 - val_accuracy: 0.8167 - val_loss: 0.5025\n",
            "Epoch 64/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8861 - loss: 0.4389 - val_accuracy: 0.8167 - val_loss: 0.5009\n",
            "Epoch 65/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8640 - loss: 0.4812 - val_accuracy: 0.8000 - val_loss: 0.5044\n",
            "Epoch 66/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8765 - loss: 0.4578 - val_accuracy: 0.8000 - val_loss: 0.5003\n",
            "Epoch 67/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9019 - loss: 0.4267 - val_accuracy: 0.8167 - val_loss: 0.4954\n",
            "Epoch 68/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8832 - loss: 0.4472 - val_accuracy: 0.8167 - val_loss: 0.4923\n",
            "Epoch 69/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8736 - loss: 0.4482 - val_accuracy: 0.8000 - val_loss: 0.4939\n",
            "Epoch 70/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8597 - loss: 0.4480 - val_accuracy: 0.8000 - val_loss: 0.4912\n",
            "Epoch 71/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8599 - loss: 0.4722 - val_accuracy: 0.8167 - val_loss: 0.4881\n",
            "Epoch 72/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8662 - loss: 0.4187 - val_accuracy: 0.8167 - val_loss: 0.4867\n",
            "Epoch 73/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8886 - loss: 0.4094 - val_accuracy: 0.8167 - val_loss: 0.4854\n",
            "Epoch 74/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8991 - loss: 0.4392 - val_accuracy: 0.8000 - val_loss: 0.4878\n",
            "Epoch 75/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8821 - loss: 0.4056 - val_accuracy: 0.8000 - val_loss: 0.4845\n",
            "Epoch 76/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8794 - loss: 0.4266 - val_accuracy: 0.8000 - val_loss: 0.4845\n",
            "Epoch 77/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8751 - loss: 0.4063 - val_accuracy: 0.8000 - val_loss: 0.4849\n",
            "Epoch 78/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8858 - loss: 0.4019 - val_accuracy: 0.8167 - val_loss: 0.4777\n",
            "Epoch 79/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8884 - loss: 0.4112 - val_accuracy: 0.8167 - val_loss: 0.4768\n",
            "Epoch 80/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8453 - loss: 0.4047 - val_accuracy: 0.8167 - val_loss: 0.4768\n",
            "Epoch 81/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8882 - loss: 0.4543 - val_accuracy: 0.8167 - val_loss: 0.4751\n",
            "Epoch 82/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8714 - loss: 0.3875 - val_accuracy: 0.8000 - val_loss: 0.4764\n",
            "Epoch 83/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8807 - loss: 0.4635 - val_accuracy: 0.8167 - val_loss: 0.4719\n",
            "Epoch 84/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8691 - loss: 0.4529 - val_accuracy: 0.8167 - val_loss: 0.4705\n",
            "Epoch 85/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8917 - loss: 0.3943 - val_accuracy: 0.8167 - val_loss: 0.4719\n",
            "Epoch 86/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8772 - loss: 0.4376 - val_accuracy: 0.8167 - val_loss: 0.4729\n",
            "Epoch 87/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9049 - loss: 0.3853 - val_accuracy: 0.8167 - val_loss: 0.4730\n",
            "Epoch 88/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8815 - loss: 0.4416 - val_accuracy: 0.8167 - val_loss: 0.4702\n",
            "Epoch 89/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8969 - loss: 0.3640 - val_accuracy: 0.8167 - val_loss: 0.4710\n",
            "Epoch 90/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9030 - loss: 0.4376 - val_accuracy: 0.8167 - val_loss: 0.4699\n",
            "Epoch 91/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8715 - loss: 0.4311 - val_accuracy: 0.8167 - val_loss: 0.4677\n",
            "Epoch 92/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9120 - loss: 0.3665 - val_accuracy: 0.8167 - val_loss: 0.4692\n",
            "Epoch 93/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8695 - loss: 0.4155 - val_accuracy: 0.8167 - val_loss: 0.4704\n",
            "Epoch 94/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8880 - loss: 0.3787 - val_accuracy: 0.8167 - val_loss: 0.4690\n",
            "Epoch 95/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9002 - loss: 0.3842 - val_accuracy: 0.8167 - val_loss: 0.4690\n",
            "Epoch 96/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8876 - loss: 0.3826 - val_accuracy: 0.8167 - val_loss: 0.4695\n",
            "Epoch 97/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8888 - loss: 0.4161 - val_accuracy: 0.8167 - val_loss: 0.4639\n",
            "Epoch 98/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8858 - loss: 0.3684 - val_accuracy: 0.8167 - val_loss: 0.4628\n",
            "Epoch 99/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8782 - loss: 0.3811 - val_accuracy: 0.8000 - val_loss: 0.4682\n",
            "Epoch 100/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9284 - loss: 0.3725 - val_accuracy: 0.8000 - val_loss: 0.4741\n",
            "Epoch 101/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 0.3887 - val_accuracy: 0.8000 - val_loss: 0.4695\n",
            "Epoch 102/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9087 - loss: 0.3620 - val_accuracy: 0.8167 - val_loss: 0.4650\n",
            "Epoch 103/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9162 - loss: 0.3891 - val_accuracy: 0.8167 - val_loss: 0.4644\n",
            "Epoch 104/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9132 - loss: 0.4112 - val_accuracy: 0.8167 - val_loss: 0.4630\n",
            "Epoch 105/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9056 - loss: 0.3892 - val_accuracy: 0.8167 - val_loss: 0.4623\n",
            "Epoch 106/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8757 - loss: 0.4035 - val_accuracy: 0.8000 - val_loss: 0.4683\n",
            "Epoch 107/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8960 - loss: 0.4124 - val_accuracy: 0.8167 - val_loss: 0.4668\n",
            "Epoch 108/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9086 - loss: 0.3583 - val_accuracy: 0.8167 - val_loss: 0.4658\n",
            "Epoch 109/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8944 - loss: 0.4116 - val_accuracy: 0.8167 - val_loss: 0.4595\n",
            "Epoch 110/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8913 - loss: 0.3881 - val_accuracy: 0.8167 - val_loss: 0.4571\n",
            "Epoch 111/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8986 - loss: 0.3859 - val_accuracy: 0.8167 - val_loss: 0.4574\n",
            "Epoch 112/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.3702 - val_accuracy: 0.8167 - val_loss: 0.4580\n",
            "Epoch 113/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9090 - loss: 0.3604 - val_accuracy: 0.8167 - val_loss: 0.4577\n",
            "Epoch 114/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8760 - loss: 0.3921 - val_accuracy: 0.8167 - val_loss: 0.4581\n",
            "Epoch 115/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8856 - loss: 0.4223 - val_accuracy: 0.8167 - val_loss: 0.4588\n",
            "Epoch 116/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9216 - loss: 0.3541 - val_accuracy: 0.8167 - val_loss: 0.4615\n",
            "Epoch 117/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8919 - loss: 0.4072 - val_accuracy: 0.8000 - val_loss: 0.4647\n",
            "Epoch 118/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8863 - loss: 0.3905 - val_accuracy: 0.8000 - val_loss: 0.4628\n",
            "Epoch 119/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8969 - loss: 0.3698 - val_accuracy: 0.8167 - val_loss: 0.4539\n",
            "Epoch 120/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8812 - loss: 0.3807 - val_accuracy: 0.8167 - val_loss: 0.4531\n",
            "Epoch 121/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.3316 - val_accuracy: 0.8167 - val_loss: 0.4513\n",
            "Epoch 122/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8755 - loss: 0.4186 - val_accuracy: 0.8167 - val_loss: 0.4504\n",
            "Epoch 123/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8826 - loss: 0.4057 - val_accuracy: 0.8167 - val_loss: 0.4517\n",
            "Epoch 124/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8902 - loss: 0.3688 - val_accuracy: 0.8167 - val_loss: 0.4565\n",
            "Epoch 125/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9074 - loss: 0.3938 - val_accuracy: 0.8167 - val_loss: 0.4570\n",
            "Epoch 126/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8796 - loss: 0.3832 - val_accuracy: 0.8167 - val_loss: 0.4489\n",
            "Epoch 127/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9325 - loss: 0.3647 - val_accuracy: 0.8167 - val_loss: 0.4467\n",
            "Epoch 128/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8994 - loss: 0.3600 - val_accuracy: 0.8167 - val_loss: 0.4468\n",
            "Epoch 129/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8912 - loss: 0.3892 - val_accuracy: 0.8167 - val_loss: 0.4503\n",
            "Epoch 130/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9028 - loss: 0.3474 - val_accuracy: 0.8000 - val_loss: 0.4572\n",
            "Epoch 131/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8972 - loss: 0.3938 - val_accuracy: 0.8167 - val_loss: 0.4539\n",
            "Epoch 132/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9406 - loss: 0.3304 - val_accuracy: 0.8167 - val_loss: 0.4534\n",
            "Epoch 133/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8855 - loss: 0.3726 - val_accuracy: 0.8167 - val_loss: 0.4546\n",
            "Epoch 134/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8999 - loss: 0.3584 - val_accuracy: 0.8000 - val_loss: 0.4524\n",
            "Epoch 135/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8923 - loss: 0.3595 - val_accuracy: 0.8167 - val_loss: 0.4503\n",
            "Epoch 136/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9144 - loss: 0.3449 - val_accuracy: 0.8000 - val_loss: 0.4535\n",
            "Epoch 137/5000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9231 - loss: 0.3450 - val_accuracy: 0.8167 - val_loss: 0.4499\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7604 - loss: 0.5596 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install tensorflow==2.17.0\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from flask import Flask, render_template, request\n",
        "\n",
        "\n",
        "def preprocess_features(X):\n",
        "    \"\"\"Preprocess features by dropping specified columns and handling numerical columns.\"\"\"\n",
        "    X_reduced = X.drop(['sex', 'serum_sodium', 'smoking', 'anaemia'], axis=1)\n",
        "    numerical_cols = X_reduced.select_dtypes(include=['number']).columns.tolist()\n",
        "    return X_reduced, numerical_cols\n",
        "\n",
        "def build_preprocessor(numerical_cols):\n",
        "    \"\"\"Build a preprocessing pipeline for numerical features.\"\"\"\n",
        "    return ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', Pipeline(steps=[\n",
        "                ('imputer', SimpleImputer(strategy='mean')),\n",
        "                ('scaler', StandardScaler())\n",
        "            ]), numerical_cols)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def apply_preprocessing(preprocessor, X_train, X_val, X_test):\n",
        "    \"\"\"Apply preprocessing to the feature sets.\"\"\"\n",
        "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "    X_val_preprocessed = preprocessor.transform(X_val)\n",
        "    X_test_preprocessed = preprocessor.transform(X_test)\n",
        "    return X_train_preprocessed, X_val_preprocessed, X_test_preprocessed\n",
        "\n",
        "def apply_smote(X_train_preprocessed, y_train):\n",
        "    \"\"\"Apply SMOTE to the training data.\"\"\"\n",
        "    smote = SMOTE(random_state=42)\n",
        "    return smote.fit_resample(X_train_preprocessed, y_train)\n",
        "\n",
        "\n",
        "# Main execution\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "X = df.drop('DEATH_EVENT', axis=1)\n",
        "y = df['DEATH_EVENT']\n",
        "\n",
        "X_reduced, numerical_cols = preprocess_features(X)\n",
        "\n",
        "preprocessor = build_preprocessor(numerical_cols)\n",
        "\n",
        "print(X_reduced.head())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_preprocessed, X_val_preprocessed, X_test_preprocessed = apply_preprocessing(preprocessor, X_train, X_val, X_test)\n",
        "\n",
        "# Apply SMOTE\n",
        "X_train_resampled, y_train_resampled = apply_smote(X_train_preprocessed, y_train)\n",
        "\n",
        "# Define and compile the neural network model\n",
        "def build_model(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=(input_shape,), kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build and train the neural network model\n",
        "model = build_model(X_train_resampled.shape[1])\n",
        "history = model.fit(X_train_resampled, y_train_resampled,\n",
        "                    validation_data=(X_val_preprocessed, y_val),\n",
        "                    epochs=5000,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_preprocessed, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Save the preprocessor and model\n",
        "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
        "model.save('model.h5')\n",
        "joblib.dump(model, 'model.pkl')\n"
      ]
    }
  ]
}